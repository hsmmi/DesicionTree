{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4 : Decision Tree & Ensemble Algorithms\n",
    "\n",
    "## STD IDs: 9931155 & 40133693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabulate import tabulate\n",
    "from DesicionTree import HDDT, preprocess, bagging, adaboost\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "DS_Covid19HDDT=\"Dataset/Covid19HDDT.csv\"\n",
    "DS_Covid= \"Dataset/Covid.csv\"\n",
    "\n",
    "max_depth=[2, 3, 4, 5]\n",
    "cut_off=[10, 50, 500]\n",
    "n_iteration=10\n",
    "threshold = 0.3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A (Decision Tree):  Dataset: Covid19HDDT.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "\n",
    "#### Convert the data to a two-class data set by keeping the smallest class as minority and the rest as majority "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.81729, 'Recall': 0.53409, 'F-measure': 0.64581, 'G-mean': 0.66057}\n"
     ]
    }
   ],
   "source": [
    "data, label = preprocess.read_dataset(DS_Covid19HDDT)\n",
    "\n",
    "label_minority_majority = preprocess.minority_0_majority_1(label)\n",
    "data = preprocess.remove_correlated_with_label_by_hellinger(\n",
    "    data=data, label=label_minority_majority, threshold=threshold\n",
    ")\n",
    "\n",
    "acc = HDDT.run_HDDT(\n",
    "    data,\n",
    "    label_minority_majority,\n",
    "    n_iteration=n_iteration,\n",
    ")\n",
    "\n",
    "print(acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle the multiclass data with OVO (One Versus One) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.96895, 'Recall': 0.96579, 'F-measure': 0.96737, 'G-mean': 0.96737}\n"
     ]
    }
   ],
   "source": [
    "data, label = preprocess.read_dataset(DS_Covid19HDDT)\n",
    "data = preprocess.remove_correlated_with_label_by_hellinger(\n",
    "    data=data, label=label, threshold=threshold\n",
    ")\n",
    "\n",
    "\n",
    "acc = HDDT.OVO(\n",
    "    data,\n",
    "    label,\n",
    "    n_iteration=n_iteration,\n",
    ")\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle the multiclass data with OVA (One Versus All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.96814, 'Recall': 0.9667, 'F-measure': 0.96741, 'G-mean': 0.96742}\n"
     ]
    }
   ],
   "source": [
    "data, label = preprocess.read_dataset(DS_Covid19HDDT)\n",
    "data = preprocess.remove_correlated_with_label_by_hellinger(\n",
    "    data=data, label=label, threshold=threshold\n",
    ")\n",
    "\n",
    "\n",
    "acc = HDDT.OVA(\n",
    "    data,\n",
    "    label,\n",
    "    n_iteration=n_iteration,\n",
    ")\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "\n",
    "#### Repeat  both  of  the  experiments  in  previous  parts  with  the  pruned  HDDT  trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision\n",
      "╒════╤═════════╤═════════╤═════════╕\n",
      "│    │      10 │      50 │     500 │\n",
      "╞════╪═════════╪═════════╪═════════╡\n",
      "│  2 │ 0.97494 │ 0.97262 │ 0.97374 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  3 │ 0.96974 │ 0.97024 │ 0.9715  │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  4 │ 0.97077 │ 0.97081 │ 0.97088 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  5 │ 0.96981 │ 0.96954 │ 0.96919 │\n",
      "╘════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "Recall\n",
      "╒════╤═════════╤═════════╤═════════╕\n",
      "│    │      10 │      50 │     500 │\n",
      "╞════╪═════════╪═════════╪═════════╡\n",
      "│  2 │ 0.96958 │ 0.97288 │ 0.97106 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  3 │ 0.97171 │ 0.97148 │ 0.96937 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  4 │ 0.96695 │ 0.96582 │ 0.96667 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  5 │ 0.96568 │ 0.96689 │ 0.96724 │\n",
      "╘════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "F-measure\n",
      "╒════╤═════════╤═════════╤═════════╕\n",
      "│    │      10 │      50 │     500 │\n",
      "╞════╪═════════╪═════════╪═════════╡\n",
      "│  2 │ 0.97222 │ 0.9727  │ 0.97234 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  3 │ 0.97071 │ 0.97085 │ 0.97042 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  4 │ 0.96885 │ 0.96831 │ 0.96876 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  5 │ 0.96774 │ 0.9682  │ 0.96821 │\n",
      "╘════╧═════════╧═════════╧═════════╛\n",
      "\n",
      "G-mean\n",
      "╒════╤═════════╤═════════╤═════════╕\n",
      "│    │      10 │      50 │     500 │\n",
      "╞════╪═════════╪═════════╪═════════╡\n",
      "│  2 │ 0.97224 │ 0.97273 │ 0.97237 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  3 │ 0.97072 │ 0.97085 │ 0.97043 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  4 │ 0.96885 │ 0.96831 │ 0.96876 │\n",
      "├────┼─────────┼─────────┼─────────┤\n",
      "│  5 │ 0.96774 │ 0.96821 │ 0.96821 │\n",
      "╘════╧═════════╧═════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "data, label = preprocess.read_dataset(DS_Covid19HDDT)\n",
    "data = preprocess.remove_correlated_with_label_by_hellinger(\n",
    "    data=data, label=label, threshold=threshold\n",
    ")\n",
    "\n",
    "acc_metrics_precision = np.empty((len(max_depth), len(cut_off)))\n",
    "acc_metrics_recall = np.empty((len(max_depth), len(cut_off)))\n",
    "acc_metrics_fmeasure = np.empty((len(max_depth), len(cut_off)))\n",
    "acc_metrics_gmean = np.empty((len(max_depth), len(cut_off)))\n",
    "\n",
    "for i in range(len(max_depth)):\n",
    "    for j in range(len(cut_off)):\n",
    "        acc_metrics = HDDT.OVA(\n",
    "            data=data,\n",
    "            label=label,\n",
    "            n_iteration=n_iteration,\n",
    "            max_depth=max_depth[i],\n",
    "            cut_off=cut_off[j],\n",
    "        )\n",
    "        acc_metrics_precision[i, j] = acc_metrics[\"Precision\"]\n",
    "        acc_metrics_recall[i, j] = acc_metrics[\"Recall\"]\n",
    "        acc_metrics_fmeasure[i, j] = acc_metrics[\"F-measure\"]\n",
    "        acc_metrics_gmean[i, j] = acc_metrics[\"G-mean\"]\n",
    "\n",
    "# Print table of result using tabulate\n",
    "print(\"Precision\")\n",
    "print(\n",
    "    tabulate(\n",
    "        acc_metrics_precision,\n",
    "        headers=cut_off,\n",
    "        showindex=max_depth,\n",
    "        tablefmt=\"fancy_grid\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nRecall\")\n",
    "print(\n",
    "    tabulate(\n",
    "        acc_metrics_recall,\n",
    "        headers=cut_off,\n",
    "        showindex=max_depth,\n",
    "        tablefmt=\"fancy_grid\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nF-measure\")\n",
    "print(\n",
    "    tabulate(\n",
    "        acc_metrics_fmeasure,\n",
    "        headers=cut_off,\n",
    "        showindex=max_depth,\n",
    "        tablefmt=\"fancy_grid\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nG-mean\")\n",
    "print(\n",
    "    tabulate(\n",
    "        acc_metrics_gmean,\n",
    "        headers=cut_off,\n",
    "        showindex=max_depth,\n",
    "        tablefmt=\"fancy_grid\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B (Ensemble Learning): Dataset: Covid.csv\n",
    "\n",
    "####  implement a bootstrap ensemble algorithm which is Bagging for imbalanced data.\n",
    "\n",
    "With HDDT base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging with base learner HDDT\n",
      "Average metrics\n",
      "╒═════╤═════════════╤══════════╤═════════════╤══════════╕\n",
      "│     │   Precision │   Recall │   F-measure │   G-mean │\n",
      "╞═════╪═════════════╪══════════╪═════════════╪══════════╡\n",
      "│  11 │     0.56887 │  0.50644 │     0.52452 │  0.53094 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  31 │     0.80327 │  0.52444 │     0.62583 │  0.64446 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  51 │     0.8295  │  0.53099 │     0.64248 │  0.66102 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│ 101 │     0.5272  │  0.50633 │     0.51216 │  0.51444 │\n",
      "╘═════╧═════════════╧══════════╧═════════════╧══════════╛\n",
      "Standard deviation metrics\n",
      "╒═════╤═════════════╤══════════╤═════════════╤══════════╕\n",
      "│     │   Precision │   Recall │   F-measure │   G-mean │\n",
      "╞═════╪═════════════╪══════════╪═════════════╪══════════╡\n",
      "│  11 │     0.2008  │  0.01539 │     0.0821  │  0.09435 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  31 │     0.19798 │  0.01366 │     0.07986 │  0.09232 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  51 │     0.15064 │  0.01543 │     0.06026 │  0.0697  │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│ 101 │     0.11889 │  0.01266 │     0.05723 │  0.06143 │\n",
      "╘═════╧═════════════╧══════════╧═════════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "data, label = preprocess.read_dataset(DS_Covid)\n",
    "label[label == -1] = 0\n",
    "data = preprocess.fill_missing_value(data=data, method=\"mode\")\n",
    "\n",
    "data = preprocess.remove_correlated_with_label_by_hellinger(\n",
    "    data=data, label=label, threshold=threshold\n",
    ")\n",
    "\n",
    "T = [11, 31, 51, 101]\n",
    "\n",
    "avg_metrics = np.empty((len(T), 4))\n",
    "std_metrics = np.empty((len(T), 4))\n",
    "\n",
    "print(\"bagging with base learner HDDT\")\n",
    "for i in range(len(T)):\n",
    "    model = bagging(T=T[i], base_learner=\"HDDT\")\n",
    "    avg, std = model.run_bagging(data=data, label=label, n_iteration=n_iteration)\n",
    "\n",
    "    avg_metrics[i][0] = avg[\"Avg-Precision\"]\n",
    "    avg_metrics[i][1] = avg[\"Avg-Recall\"]\n",
    "    avg_metrics[i][2] = avg[\"Avg-F-measure\"]\n",
    "    avg_metrics[i][3] = avg[\"Avg-G-mean\"]\n",
    "    std_metrics[i][0] = std[\"Std-Precision\"]\n",
    "    std_metrics[i][1] = std[\"Std-Recall\"]\n",
    "    std_metrics[i][2] = std[\"Std-F-measure\"]\n",
    "    std_metrics[i][3] = std[\"Std-G-mean\"]\n",
    "\n",
    "    \n",
    "print(\"Average metrics\")\n",
    "print(\n",
    "    tabulate(\n",
    "        avg_metrics,\n",
    "        headers=[\"Precision\", \"Recall\", \"F-measure\", \"G-mean\"],\n",
    "        showindex=T,\n",
    "        tablefmt=\"fancy_grid\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Standard deviation metrics\")\n",
    "print(\n",
    "    tabulate(\n",
    "        std_metrics,\n",
    "        headers=[\"Precision\", \"Recall\", \"F-measure\", \"G-mean\"],\n",
    "        showindex=T,\n",
    "        tablefmt=\"fancy_grid\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Built-in base learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging with base learner Built-in\n",
      "T =  11\n",
      "T =  31\n",
      "T =  51\n",
      "T =  101\n",
      "Average metrics\n",
      "╒═════╤═════════════╤══════════╤═════════════╤══════════╕\n",
      "│     │   Precision │   Recall │   F-measure │   G-mean │\n",
      "╞═════╪═════════════╪══════════╪═════════════╪══════════╡\n",
      "│  11 │     0.57522 │  0.7808  │     0.66196 │  0.66993 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  31 │     0.57733 │  0.79948 │     0.67004 │  0.67916 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  51 │     0.5809  │  0.81007 │     0.67633 │  0.68584 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│ 101 │     0.5742  │  0.78845 │     0.66383 │  0.67252 │\n",
      "╘═════╧═════════════╧══════════╧═════════════╧══════════╛\n",
      "Standard deviation metrics\n",
      "╒═════╤═════════════╤══════════╤═════════════╤══════════╕\n",
      "│     │   Precision │   Recall │   F-measure │   G-mean │\n",
      "╞═════╪═════════════╪══════════╪═════════════╪══════════╡\n",
      "│  11 │     0.01716 │  0.06236 │     0.03473 │  0.03722 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  31 │     0.01634 │  0.06199 │     0.0335  │  0.03629 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  51 │     0.01432 │  0.05172 │     0.02811 │  0.03051 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│ 101 │     0.01889 │  0.07191 │     0.03965 │  0.04249 │\n",
      "╘═════╧═════════════╧══════════╧═════════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "data, label = preprocess.read_dataset(DS_Covid)\n",
    "label[label == -1] = 0\n",
    "data = preprocess.fill_missing_value(data=data, method=\"mode\")\n",
    "\n",
    "data = preprocess.remove_correlated_with_label_by_hellinger(\n",
    "    data=data, label=label, threshold=threshold\n",
    ")\n",
    "\n",
    "T = [11, 31, 51, 101]\n",
    "\n",
    "avg_metrics = np.empty((len(T), 4))\n",
    "std_metrics = np.empty((len(T), 4))\n",
    "\n",
    "print(\"bagging with base learner Built-in\")\n",
    "for i in range(len(T)):\n",
    "    print(\"T = \", T[i])\n",
    "    model = bagging(T=T[i], base_learner=\"Built-in\")\n",
    "    avg, std = model.run_bagging(data=data, label=label, n_iteration=n_iteration)\n",
    "\n",
    "    avg_metrics[i][0] = avg[\"Avg-Precision\"]\n",
    "    avg_metrics[i][1] = avg[\"Avg-Recall\"]\n",
    "    avg_metrics[i][2] = avg[\"Avg-F-measure\"]\n",
    "    avg_metrics[i][3] = avg[\"Avg-G-mean\"]\n",
    "    std_metrics[i][0] = std[\"Std-Precision\"]\n",
    "    std_metrics[i][1] = std[\"Std-Recall\"]\n",
    "    std_metrics[i][2] = std[\"Std-F-measure\"]\n",
    "    std_metrics[i][3] = std[\"Std-G-mean\"]\n",
    "\n",
    "    \n",
    "print(\"Average metrics\")\n",
    "print(\n",
    "    tabulate(\n",
    "        avg_metrics,\n",
    "        headers=[\"Precision\", \"Recall\", \"F-measure\", \"G-mean\"],\n",
    "        showindex=T,\n",
    "        tablefmt=\"fancy_grid\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Standard deviation metrics\")\n",
    "print(\n",
    "    tabulate(\n",
    "        std_metrics,\n",
    "        headers=[\"Precision\", \"Recall\", \"F-measure\", \"G-mean\"],\n",
    "        showindex=T,\n",
    "        tablefmt=\"fancy_grid\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method II: Adaboost with UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DT:\n",
      "[0.54927 0.54833 0.5488  0.5488 ]\n",
      "\n",
      "Accuracy My AdaBoost:\n",
      "[0.56092 0.56    0.56046 0.56046]\n",
      "\n",
      "Accuracy Built-in AdaBoost:\n",
      "[0.57981 0.57667 0.57822 0.57823]\n",
      "\n",
      "Accuracy Adaboost with 10 iteration for different number of classifiers\n",
      "╒═════╤═════════════╤══════════╤═════════════╤══════════╕\n",
      "│     │   Precision │   Recall │   F-measure │   G-mean │\n",
      "╞═════╪═════════════╪══════════╪═════════════╪══════════╡\n",
      "│  11 │     0.57012 │  0.565   │     0.56752 │  0.56754 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  31 │     0.55567 │  0.55333 │     0.5545  │  0.5545  │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  51 │     0.54412 │  0.54333 │     0.54372 │  0.54372 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│ 101 │     0.57417 │  0.57167 │     0.57291 │  0.57291 │\n",
      "╘═════╧═════════════╧══════════╧═════════════╧══════════╛\n",
      "\n",
      "Accuracy Adaboost with 15 iteration for different number of classifiers\n",
      "╒═════╤═════════════╤══════════╤═════════════╤══════════╕\n",
      "│     │   Precision │   Recall │   F-measure │   G-mean │\n",
      "╞═════╪═════════════╪══════════╪═════════════╪══════════╡\n",
      "│  11 │     0.54319 │  0.54111 │     0.54214 │  0.54214 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  31 │     0.53146 │  0.53111 │     0.53128 │  0.53128 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│  51 │     0.53458 │  0.53444 │     0.53451 │  0.53451 │\n",
      "├─────┼─────────────┼──────────┼─────────────┼──────────┤\n",
      "│ 101 │     0.5622  │  0.56111 │     0.56165 │  0.56165 │\n",
      "╘═════╧═════════════╧══════════╧═════════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "data, label = preprocess.read_dataset(DS_Covid)\n",
    "label[label == -1] = 0\n",
    "data = preprocess.fill_missing_value(data=data, method=\"mode\")\n",
    "\n",
    "data = preprocess.remove_correlated_with_label_by_hellinger(\n",
    "    data=data, label=label, threshold=threshold\n",
    ")\n",
    "\n",
    "# balance imbalance data with under_sampling\n",
    "data, label = preprocess.bootstrap_with_under_sampling(data, label)\n",
    "\n",
    "\n",
    "acc_DT = np.empty((0, 4))\n",
    "acc_my_adaboost = np.empty((0, 4))\n",
    "acc_biultin_adaboost = np.empty((0, 4))\n",
    "\n",
    "for _ in range(n_iteration):\n",
    "    # Split train and test\n",
    "    data_train, data_test, label_train, label_test = train_test_split(\n",
    "        data, label, test_size=0.3, stratify=label\n",
    "    )\n",
    "\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(data_train, label_train)\n",
    "    predicted = clf.predict(data_test)\n",
    "    acc = preprocess.accuracy(predicted, label_test)\n",
    "    acc_DT = np.vstack((acc_DT, acc))\n",
    "\n",
    "    model = adaboost(11)\n",
    "    model.fit(data_train, label_train)\n",
    "    predicted = model.predict(data_test)\n",
    "    acc = preprocess.accuracy(predicted, label_test)\n",
    "    acc_my_adaboost = np.vstack((acc_my_adaboost, acc))\n",
    "\n",
    "    clf = AdaBoostClassifier()\n",
    "    clf.fit(data_train, label_train)\n",
    "    predicted = clf.predict(data_test)\n",
    "    acc = preprocess.accuracy(predicted, label_test)\n",
    "    acc_biultin_adaboost = np.vstack((acc_biultin_adaboost, acc))\n",
    "\n",
    "acc_DT = np.mean(acc_DT, axis=0).round(5)\n",
    "print(f\"Accuracy DT:\\n{acc_DT}\\n\")\n",
    "\n",
    "acc_my_adaboost = np.mean(acc_my_adaboost, axis=0).round(5)\n",
    "print(f\"Accuracy My AdaBoost:\\n{acc_my_adaboost}\\n\")\n",
    "\n",
    "acc_biultin_adaboost = np.mean(acc_biultin_adaboost, axis=0).round(5)\n",
    "print(f\"Accuracy Built-in AdaBoost:\\n{acc_biultin_adaboost}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "n_classifiers = [11, 31, 51, 101]\n",
    "\n",
    "tabel_adaboost_10 = np.empty((0, 4))\n",
    "\n",
    "for classifiers in n_classifiers:\n",
    "    acc_adaboost = np.empty((0, 4))\n",
    "    for _ in range(10):\n",
    "        # Split train and test\n",
    "        data_train, data_test, label_train, label_test = train_test_split(\n",
    "            data, label, test_size=0.3, stratify=label\n",
    "        )\n",
    "        model = adaboost(T=classifiers)\n",
    "        model.fit(data_train, label_train)\n",
    "        predicted = model.predict(data_test)\n",
    "        acc = preprocess.accuracy(predicted, label_test)\n",
    "        acc_adaboost = np.vstack((acc_adaboost, acc))\n",
    "\n",
    "    acc_adaboost = np.mean(acc_adaboost, axis=0).round(5)\n",
    "    tabel_adaboost_10 = np.vstack((tabel_adaboost_10, acc_adaboost))\n",
    "\n",
    "\n",
    "tabel_adaboost_15 = np.empty((0, 4))\n",
    "\n",
    "for classifiers in n_classifiers:\n",
    "    acc_adaboost = np.empty((0, 4))\n",
    "    for _ in range(15):\n",
    "        # Split train and test\n",
    "        data_train, data_test, label_train, label_test = train_test_split(\n",
    "            data, label, test_size=0.3, stratify=label\n",
    "        )\n",
    "        model = adaboost(T=classifiers)\n",
    "        model.fit(data_train, label_train)\n",
    "        predicted = model.predict(data_test)\n",
    "        acc = preprocess.accuracy(predicted, label_test)\n",
    "        acc_adaboost = np.vstack((acc_adaboost, acc))\n",
    "\n",
    "    acc_adaboost = np.mean(acc_adaboost, axis=0).round(5)\n",
    "    tabel_adaboost_15 = np.vstack((tabel_adaboost_15, acc_adaboost))\n",
    "\n",
    "print(\n",
    "    \"Accuracy Adaboost with 10 iteration for different number of classifiers\"\n",
    ")\n",
    "print(\n",
    "    tabulate(\n",
    "        tabel_adaboost_10,\n",
    "        headers=[\"Precision\", \"Recall\", \"F-measure\", \"G-mean\"],\n",
    "        tablefmt=\"fancy_grid\",\n",
    "        showindex=n_classifiers,\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"\\nAccuracy Adaboost with 15 iteration for different number of classifiers\"\n",
    ")\n",
    "print(\n",
    "    tabulate(\n",
    "        tabel_adaboost_15,\n",
    "        headers=[\"Precision\", \"Recall\", \"F-measure\", \"G-mean\"],\n",
    "        tablefmt=\"fancy_grid\",\n",
    "        showindex=n_classifiers,\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
